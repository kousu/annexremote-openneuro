#!/usr/bin/env python3

"""
cli client for https://openneuro.org

(this is an alternative to https://github.com/OpenNeuroOrg/openneuro/blob/master/packages/openneuro-cli/)
"""

import os
import io
import random
import posixpath
import logging

import json
from getpass import getpass

import click
from progressbar import *

import openneuro


class ProgressFile(io.IOBase):
    """
    A shim which reports progress in reading/writing.

    >>> fp = open("yourfile", "rb")
    >>> fp = ProgressFile(fp, lambda pos: print(f'Now at: {pos}'))
    >>> with open("yourfile (copy)", "wb") as out:
    ...    for chunk in ....

    The motivation for this is to extract progress information
    from deep inside libraries that wouldn't normally have a way
    to report it.
    """
    def __init__(self, stream, callback):
        self.wrapped = stream
        self.callback = callback

    def read(self, size, *args, **kwargs):
        try:
            return self.wrapped.read(size, *args, **kwargs)
        finally:
            self.callback(self.wrapped.tell())

    def write(self, *args, **kwargs):
        try:
            return self.wrapped.write(*args, **kwargs)
        finally:
            self.callback(self.wrapped.tell())

    def __getattr__(self, name):
        # recall: this is only run as a fallback
        return getattr(self.wrapped, name)


class UnsortedGroup(click.Group):
    """
    """
    # https://stackoverflow.com/questions/47972638/how-can-i-define-the-order-of-click-sub-commands-in-help
    def list_commands(self, *args, **kwargs):
        return list(self.commands)

@click.group(cls=UnsortedGroup)
def cli():
    pass

@cli.command()
@click.option("--server", "-s", default="https://openneuro.org", help="Specify server to connect to.")
def login(server):
    """
    Login to openneuro using your API token.

    You can get an auth token from https://openneuro.org/genkey.
    """
    token = getpass("OpenNeuro API Token: ")

    # TODO: test credentials by connecting to server and trying to use them before accepting them

    with open(os.path.expanduser("~/.openneuro"), "w") as fp: # TODO: Windows??
        json.dump({'url': server, 'apikey': token}, fp)

def credentials():
    """
    Try to load credentials to access OpenNeuro.

    Environment variables
     OPENNEURO_SERVER
     OPENNEURO_TOKEN
    has the highest precedence, followed by JSON file
     ~/.openneuro
    if either can't be found, returns None for its value.

    Returns (server, token)
    """
    server, token = 'https://openneuro.org', None

    try:
        with open(os.path.expanduser("~/.openneuro"), "r") as fp: # TODO: Windows??
            obj = json.load(fp) # XXX is this deserialization dangerous?
            server = obj.get('server', server)
            token = obj.get('apikey', token)
    except:
        logging.exception("Couldn't load credentials from ~/.openneuro") # DEBUG
        pass

    server = os.environ.get('OPENNEURO_SERVER', server)
    token = os.environ.get('OPENNEURO_TOKEN', token)

    return server, token

#@cli.option("--delete"):
@cli.command()
@click.option("-f", "--force", is_flag=True, help="Automatically create a new dataset if needed.")
@click.argument("dataset", required=False)
@click.argument("path", required=False, type=click.Path(exists=True, file_okay=False, dir_okay=True, readable=True))
def upload(force, dataset, path):
    """
    Upload the contents of PATH to DATASET.

    If PATH is not given, the current directory is assumed.

    If DATASET is not given, a new dataset will be created.
    """
    if path is None:
        path = "."

    server, token = credentials()
    client = openneuro.Client(token, server=server)

    if dataset is None:
        # make a new dataset
        def prompt():
            while True: # there's gotta be a prompt-until-match in the stdlib somewhere
                r = input("Make a new dataset? [y/N] ").strip()
                if not r:
                    r = 'N'
                if r.upper() == 'Y':
                    return True
                elif r.upper() == 'N':
                    return False
                else:
                    continue # bad input, try again
        if force or prompt():
            dataset = client.createDataset()
            print(f'Created {client.server}/datasets/{dataset}')
        else:
            return # no dataset means nothing to do

    remote_files = client.files(dataset)
    remote_files = {m['filename']: m for m in remote_files}

    for dir, _, files in os.walk(path):
        for file in files:
            # NB: we have to use posixpath on the remote side, but os.path locally
            local_fname = os.path.join(dir, file)
            remote_fname = posixpath.join(dir, file)

            if remote_fname in remote_files:
                if remote_files[remote_fname]['size'] == os.stat(local_fname).st_size:
                    # already uploaded
                    # (openneuro doesn't key files by hash, https://github.com/OpenNeuroOrg/openneuro/issues/805#issuecomment-648367628
                    #  so the only thing we can do is check the filesize to guess if it's the same or not :( )
                    continue

            try:
                widgets = [f'{remote_fname}: ', Percentage(), ' ', Bar(marker=RotatingMarker()),
                           ' ', ETA(), ' ', FileTransferSpeed()]
                pbar = ProgressBar(widgets=widgets, maxval=os.stat(local_fname).st_size)
                pbar.start()
                fp = open(local_fname, 'rb') # TODO: close
                fp = ProgressFile(fp, pbar.update)
                # this progress bar hack is fine for now
                # but if we switch to it might not scale, because it requires pre-opening every single file

                client.uploadFile(dataset, fp, remote_fname)
                pbar.finish()
            except:
                logging.exception("Unable to upload {fname}")
                continue

@cli.command()
@click.argument("dataset")
@click.option("--version", "-v", help="Dataset version (e.g. '1.2.9').")
@click.argument("path", required=False, type=click.Path(exists=True, file_okay=False, dir_okay=True, writable=True))
def download(version, dataset, path):
    """
    Download the contents of DATASET to PATH.

    If PATH is not given, the current directory is assumed.
    """
    if path is None:
        path = "."

    server, token = credentials()
    client = openneuro.Client(token, server=server)

    for m in client.files(dataset, version=version):
        local_fname = os.path.join(path, m['filename']) # XXX fix the directory traversal vuln here
            # XXX *also* this isn't windows compatible; I need to parse m['filename'] using posixpath
            # and reconstruct it using os.path
        remote_fname = m['filename']

        if os.path.exists(local_fname):
            if os.stat(local_fname).st_size == m['size']:
                # already downloaded
                # (openneuro doesn't key files by hash, https://github.com/OpenNeuroOrg/openneuro/issues/805#issuecomment-648367628
                #  so the only thing we can do is check the filesize to guess if it's the same or not :( )
                continue

        os.makedirs(os.path.dirname(local_fname), exist_ok=True)
        try:
            # TODO: skip pre-existing files
            # TODO: --delete flag

            widgets = [f'{local_fname}: ', Percentage(), ' ', Bar(marker=RotatingMarker()),
                       ' ', ETA(), ' ', FileTransferSpeed()]
            pbar = ProgressBar(widgets=widgets, maxval=m['size'])
            pbar.start()
            fp = open(local_fname, 'wb') # TODO: close
            fp = ProgressFile(fp, pbar.update)
            # ugh this is gross: because openneuro doesn't provide a good way
            # to get per-file metadata -- it expects you to batch download it
            # -- we have to call the private _download helper.
            # maybe this can be fixed? add a cache keyed by file ID?
            client._download(random.choice(m['urls']), fp)
            pbar.finish()
        except Exception:
            # log it but continue
            logging.exception(f"Unable to download {m['filename']}")
            continue


    # TODO: use click.CommandCollection <https://click.palletsprojects.com/en/7.x/commands/#merging-multi-commands>
    # to avoid the code duplication by making a single group whose code does the logging in / etc ?

@cli.command()
@click.argument("dataset")
def publish(dataset):
    """
    Make DATASET publically available.

    On the main https://openneuro.org instance, this will also
    cause it to be exported to https://github.com/OpenNeuroDatasets.
    """
    server, token = credentials()
    print(server, token)
    client = openneuro.Client(token, server=server)

    client.publishDataset(dataset)

if __name__ == '__main__':
    cli()
