#!/usr/bin/env python3

"""
cli client for https://openneuro.org

(this is an alternative to https://github.com/OpenNeuroOrg/openneuro/blob/master/packages/openneuro-cli/)
"""

import os
import io
import posixpath
import logging

import json
from getpass import getpass

import click
from progressbar import *

import openneuro


class ProgressFile(io.IOBase):
    """
    A shim which reports progress in reading/writing.

    >>> fp = open("yourfile", "rb")
    >>> fp = ProgressFile(fp, lambda pos: print(f'Now at: {pos}'))
    >>> with open("yourfile (copy)", "wb") as out:
    ...    for chunk in ....

    The motivation for this is to extract progress information
    from deep inside libraries that wouldn't normally have a way
    to report it.
    """
    def __init__(self, stream, callback):
        self.wrapped = stream
        self.callback = callback

    def read(self, size, *args, **kwargs):
        try:
            return self.wrapped.read(size, *args, **kwargs)
        finally:
            self.callback(self.wrapped.tell())

    def write(self, *args, **kwargs):
        try:
            return self.wrapped.write(*args, **kwargs)
        finally:
            self.callback(self.wrapped.tell())

    def __getattr__(self, name):
        # recall: this is only run as a fallback
        return getattr(self.wrapped, name)


@click.group()
def cli():
    pass

@cli.command()
def login():
    server = input("Server [https://openneuro.org]: ")
    if not server.strip():
        server = 'https://openneuro.org'
    token = getpass("OpenNeuro API Token: ")

    # TODO: test credentials by connecting to server and trying to use them before accepting them

    with open(os.path.expanduser("~/.openneuro"), "w") as fp: # TODO: Windows??
        json.dump({'url': server, 'apikey': token}, fp)


def credentials():
    """
    Try to load credentials to access OpenNeuro.

    Environment variables
     OPENNEURO_SERVER
     OPENNEURO_TOKEN
    has the highest precedence, followed by JSON file
     ~/.openneuro
    if either can't be found, returns None for its value.

    Returns (server, token)
    """
    server, token = 'https://openneuro.org', None

    try:
        with open(os.path.expanduser("~/.openneuro"), "r") as fp: # TODO: Windows??
            obj = json.load(fp) # XXX is this deserialization dangerous?
            server = obj.get('server', server)
            token = obj.get('apikey', token)
    except:
        logging.exception("Couldn't load credentials from ~/.openneuro") # DEBUG
        pass

    server = os.environ.get('OPENNEURO_SERVER', server)
    token = os.environ.get('OPENNEURO_TOKEN', token)

    return server, token

#@cli.option("--delete"):
@cli.command()
@click.argument("dataset", required=False)
@click.argument("path", required=False, type=click.Path(exists=True, file_okay=False, dir_okay=True, readable=True))
def upload(dataset, path):
    """
    Upload the contents of PATH to DATASET.

    If PATH is not given, the current directory is assumed.

    If DATASET is not given, a new dataset will be created.
    """
    if path is None:
        path = "."

    server, token = credentials()
    client = openneuro.Client(token, server=server)

    if dataset is None:
        # make a new dataset
        while True: # there's gotta be a prompt-until-match in the stdlib somewhere
            r = input("Make a new dataset? [y/N] ").strip()
            if not r:
                r = 'N'
            if r.upper() == 'Y':
                dataset = client.createDataset()
                print(f'Created {server}/datasets/{dataset}')
                break
            elif r.upper() == 'N':
                return
            else:
                continue # bad input, try again

    for dir, _, files in os.walk(path):
        for file in files:
            fname = os.path.join(dir, file)

            try:
                widgets = [f'{fname}: ', Percentage(), ' ', Bar(marker=RotatingMarker()),
                           ' ', ETA(), ' ', FileTransferSpeed()]
                pbar = ProgressBar(widgets=widgets, maxval=os.stat(fname).st_size)
                pbar.start()
                fp = open(fname, 'rb')
                fp = ProgressFile(fp, pbar.update)
                # this progress bar hack is fine for now
                # but if we switch to it might not scale, because it requires pre-opening every single file

                # NB: we have to use posixpath on the remote side, but os.path locally
                client.uploadFile(dataset, fp, posixpath.join(dir, file))
                pbar.finish()
            except:
                logging.exception("Unable to upload {fname}")
                continue
                                `

@cli.command()
@click.argument("dataset")
@click.option("--version", "-v", help="Dataset version (e.g. '1.2.9')")
@click.argument("path", required=False, type=click.Path(exists=True, file_okay=False, dir_okay=True, writable=True))
def download(version, dataset, path):
    if path is None:
        path = "."

    server, token = credentials()
    print(server, token)
    client = openneuro.Client(token, server=server)

    client.downloadDataset(dataset, version=version, path=path)

    # TODO: use click.CommandCollection <https://click.palletsprojects.com/en/7.x/commands/#merging-multi-commands>
    # to avoid the code duplication by making a single group whose code does the logging in / etc ?

@cli.command()
@click.argument("dataset")
def publish(dataset):
    server, token = credentials()
    print(server, token)
    client = openneuro.Client(token, server=server)

    client.publishDataset(dataset)

if __name__ == '__main__':
    cli()
